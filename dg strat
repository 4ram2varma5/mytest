# Create a Spark session
spark = SparkSession.builder.getOrCreate()

# Convert Pandas DataFrame toSpark DataFrame
spark_df = spark.createDataFrame(df_read_example)

# Specify the options and save the Spark DataFrame as a Delta Lake table
spark_df.write.mode("overwrite").format("delta").saveAsTable("a1_dlk.twdigitalpilot.test1")

query = f"""
            SELECT *
            from a1_dlk.twdigitalpilot.test1       
            where zip_code = 35233      
            and measure_name like 'Acute Myo%'
         """
print(query)
result = spark.sql(query)
 
df = result.toPandas()

df
curious how long this function might take (SAS and SQL provide this in the log)
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%time 

#Let's Pull data from Populations Health's most commonly used tables:
#we'll be using PySpark to create the data frame for the 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

date="2024-02-15" 
query = f"""
            select *
            from pr_dlk.stg_edwh_reg1.facets_member            
            limit 10
         """
print(query)
result = spark.sql(query)

#Create a temporary View
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#result.createOrReplaceTempView("abc")

#Display the spark SQL output
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#result.display()

#Another way to access the TempView that you created
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#%sql 
#select * from abc


#Convert to Pandas Data Frame
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
df = result.toPandas()

#Contents
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# ".info()": The `dataframe.info()` function in Pandas proves to be an invaluable tool for obtaining a succinct summary of a dataframe.
df.info()

# The describe() method returns description of the data in the DataFrame.
df.describe()

# The head allows you to view headers only rows
df.head(0)

# To be compliant and protect our member information, We are using summarized data
%time
#Last Quarter of 2023
query = f"""
            SELECT *
            from pr_dlk.stg_mreplus.converged_rate_summary
            where month (to_date (rec_creation_time)) in (10)
            and year (to_date (rec_creation_time)) = 2023
            and reporting_population_name	 = 'FL_Medicaid'
            
         """
print(query)
result = spark.sql(query)
df = result.toPandas()
df.head(1)
